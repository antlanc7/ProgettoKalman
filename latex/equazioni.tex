\section{Equazioni del filtro}

Il filtro di Kalman è un'implementazione ricorsiva degli algoritmi di stima che risolve il problema della ricostruzione dello stato di un sistema lineare.

Sia $\hat{x}_k$ la stima $k$-esima dello stato $x_k$ , e sia questa stima gaussiana a error medio nullo ($E[e_k] = 0$) con covarianza $P_k=E[e_ke_k^T]$.

Desiderando costruire una stima $\hat{x}_{k+1}$, dovremo tenere conto di due sor-
genti di informazione, la conoscenza del modello (mediante l’utilizzo della
legge di propagazione dello stato) e la conoscenza delle misure. Distinguiamo
quindi due diverse stime di $x_k$, una prima $\hat{x}_k^-$ costruita conoscendo le misure sino $y_{k-1}$, ed una seconda $\hat{x}_k$, che utilizza anche la misura $y_{k}$.

Basandoci sui risultati della sezione precedente, costruiamo quindi le stime:
\begin{align}
\hat{x}_k^- &= A_k\hat{x}_{k-1} + B_ku_k \\
P_k^- &= A_kP_{k-1}A_k^T + B^w_kQ_k(B^w_k)^T \\
L_k &= P_k^-C_k^T(C_kP_k^-C_k^T + R_k)^{-1}\\
\hat{x}_k &= \hat{x}_k^- + L_k(y_k - C_k\hat{x}_k^-)\\
P_k &= (I - L_kC_k)P_k^-
\end{align}

L’algoritmo così descritto prende il nome di filtro di Kalman discreto. \\ Il guadagno della innovazione nel filtro, $L_k$ è fondamentalmente un rapporto tra la incertezza nella stima dello stato P e la incertezza nella misura R: conseguentemente, se le misure sono molto accurate (R piccola), la nuova stima $\hat{x}_k$ sarà poco legata alla precedente. Se viceversa sono disponibili misure poco affidabili ma vecchie stime relativamente buone, si propagheranno queste nel futuro appoggiandosi sostanzialmente al modello del sistema.

\newpage

\textbf{ROBA NUOVA}

Come osservato nel precedente paragafo, l’algoritmo (7.3.11)-(7.3.12) propaga in realtà
una stima $\hat{x}_k$, e la relativa covarianza $P_k$ , dello stato $x_k$ basata sulle osservazioni passate
$y_{0:k-1}$ , ovvero effettua la predizione ad un passo dello stato. Per questo motivo, nel seguito
le quantità $\hat{x}_k$ e $P_k$ in (7.3.11)-(7.3.13) verranno indicate in modo più appropriato come $\hat{x}_{k|k-1}=\hat{x}_k$, e rispettivamente, $P_{k|k-1}=P_k$.\\
In molte applicazioni pratiche, l’obiettivo è quello di ottenere, ad ogni istante k, una stima dello stato $x_k$, e la relativa covarianza, basata su tutte le osservazioni $y_{0:k}  = y_{0:k-1}\cup{y_k}$, inclusa quella presente, acquisite fino all’istante k.\\
Il problema in oggetto, noto come filtraggio, è finalizzato alla determinazione della cosiddetta stima filtrata $\hat{ x}_{ k|k}$ dello stato $x_k$ basata sulle osservazioni$y_{0:k}$ e della relativa covarianza $P_{k|k} = E[\tilde{x}_{k|k}\tilde{x}_{k|k}^T]$ ,con $\tilde{x}_{k|k}\stackrel{\Delta}{=}\tilde{x}_k-\hat{x}_{k|k}$.
A tale scopo, si possono considerare $\hat{x}_{k|k}$ e  $P_{k|k}$ come stima e covarianza a-posteriori della variabile aleatoria $x_k$, a partire da stima e covarianza a priori $\hat{x}_{k|k-1}$ e $P_{k|k-1}$ ,sulla base dell'osservazione $y_k$ in(7.14),utilizzando il metodo di stima blue. In altri termini, date le statistiche a priori $(\hat{x}_{k|k-1},P_{k|k-1})$ e l’osservazione lineare $y_k=C_kx_k+v_k$ di $x_k$ si vogliono determinare le statistiche a posteriori $(\hat{x}_{k|k},P_{k|k})$ di $x_k$ mediante stima BLUE. Si ricorda che stima e covarianza a posteriori blue sono fornite da\\
\begin{equation}
\hat{x}_{k|k}=\hat{x}_{k|k-1}+\underbrace{E[\tilde{x}_{k|k-1}\tilde{y}_{k|k-1}^T]E[\tilde{y}_{k|k-1}\tilde{y}_{k|k-1}^T]^{-1}}_{L_k}(y_k-\hat{y}_{k|k-1})
\end{equation}

\begin{equation}
P_{k|k}=P_{k|k-1}-E[\tilde{x}_{k|k-1}\tilde{y}_{k|k-1}^T]E[\tilde{y}_{k|k-1}\tilde{y}_{k|k-1}^T]^{-1}E[\tilde{x}_{k|k-1}\tilde{y}_{k|k-1}^T]^T
\end{equation}

dove

\begin{align}
\hat{y}_{k|k-1} &= E[y_k]=C_k\hat{x}_{k|k-1} \\
\tilde{y}_{k|k-1} &= y_k-\hat{y}_{k|k-1}=C_k\tilde{x}_{k|k-1}+v_k
\end{align}

\begin{equation}
E[\tilde{x}_{k|k-1}\tilde{y}_{k|k-1}^T]=P_{k|k-1}C_k^T
\end{equation}

\[E[\tilde{y}_{k|k-1}\tilde{y}_{k|k-1}^T]=R_k+C_kP_{k|k-1}C_k^T\]

Sostituendo (6.3) in (6.1)-(6.2) si ottengono le seguenti equazioni di aggiornamento da $\hat{x}_{k|k-1},P_{k|k-1}$a$\hat{x}_{k|k},P_{k|k}$:

\begin{equation}
\hat{x}_{k|k}=\hat{x}_{k|k-1}+L_k(y_k-C_k\hat{x}_{k|k-1})
\end{equation}


\begin{equation}
P_{k|k}=P_{k|k-1}-P_{k|k-1}C_k^T(R_k+C_kP_{k|k-1}C_k^T)^{-1}C_kP_{k|k-1}
\end{equation}

con

\begin{equation}
L_k=P_{k|k-1}C_k^T(R_k+C_kP_{k|k-1}C_k^T)^{-1}
\end{equation}

Le equazioni (6.4)-(6.5) consentono di correggere la stima predittiva $\hat{x}_{k|k-1} $e la relativa covarianza $P_{k|k-1} $ con l’ultima osservazione $y_k $, per ottenere la stima filtrata $\hat{x}_{k|k} $ e relativa covarianza $P_{k|k} $.\\
Per questo motivo (6.4)-(6.5) vengono dette equazioni di correzione
della stima e, rispettivamente, della covarianza e la matrice $L_k$ in (6.6) prende il nome di guadagno di correzione.\\
Si noti che, posto $K_k=A_kL_k $, l’equazione di aggiornamento della stima (7.3.12) può essere espressa come segue

\begin{equation}
\hat{x}_{k+1|k}=A_k\underbrace{[\hat{x}_{k|k-1}+L_k(y_k-C_k\hat{x}_{k|k-1})]}_{\hat{x}_{k|k}	}+b_k
\end{equation}

La precedente relazione esprime la stima predittiva ad un passo $\hat{x}_{k+1|k} $ come il risultato dell’applicazione del modello di stato (7.1.3), per $w_k=0 $, alla stima filtrata $\hat{x}_{k|k}$.
Analogamente, l’equazione di aggiornamento della covarianza (7.3.13) può essere riscritta
come

\begin{equation}
P_{k+1|k}=A_k\underbrace{[P_{k|k-1}-P_{k|k-1}C_k^T(R_k+C_kP_{k|k-1}C_k^T)^{-1}C_kP_{k|k-1}]}_{P_{k|k}}A_k^T+W_kQ_kW_k^T
\end{equation}

Pertanto, si ottengono le seguenti equazioni di predizione da $(\hat{x}_{k|k},P_{k|k})$ a $(\hat{x}_{k+1|k},P_{k+1|k}) $

\begin{equation}
\hat{x}_{k+1|k}=A_k\hat{x}_{k|k}+b_k
\end{equation}


\begin{equation}
P_{k+1|k}=A_{k|k}P_{k|k}A_k^T+W_kQ_kW_k^T
\end{equation}

Riassumendo i precedenti sviluppi, la ricorsione (7.3.12)-(7.3.13) del filtro di Kalman può
essere suddivisa in due fasi diverse: la correzione (4)-(5) seguita dalla predizione
(9)-(10). La forma correzione-predizione del filtro di Kalman viene di seguito
riportata.
\newpage

\underline{\textbf{Filtro di Kalman nella forma correzione-predizione}}\\\\
\textbf{Dati} :
\begin{itemize}
\item matrici : $A_k$, $C_k$, $W_k$, $Q_k$, $R_k$;
\item stima iniziale : $\hat{x}_{1|0}$; 
\item covarianza iniziale : $P_{1|0}$;
\item $k=1,2... $
\end{itemize}
\textbf{Correzione:}
\begin{align}
S_k&=R_k+C_kP_{k|k-1}C_k^T ~~ covarianza~dell’innovazione \nonumber \\
L_k&=P_{k|k-1}C_k^TS_k^{-1}~~ guadagno~ di~ correzione \nonumber \\
e_k&=y_k-C_k\hat{x}_{k|k-1}~~ innovazione \nonumber \\
\hat{x}_{k|k}&=\hat{x}_{k|k-1}+L_ke_k~~ correzione ~della~ stima\nonumber\\
P_{k|k}&=P_{k|k-1}-L_kS_kL_k^T~ correzione ~della ~covarianza\nonumber\\
&=(I-L_kC_k)P_{k|k-1}(I-L_kC_k)^T+L_kR_kL_k^T\nonumber
\end{align}
\textbf{Predizione:}
\begin{align}
\hat{x}_{k+1|k}&=A_k\hat{x}_{k|k}+b_k~~ predizione~ della~ stima\nonumber\\
P_{k+1|k}&=A_kP_{k|k}A_k^T+W_kQ_kW_k^T~~ predizione~ della~ covarianza\nonumber
\end{align}

\newpage

\newpage